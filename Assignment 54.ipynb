{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c888859f-4570-42b5-9070-d42466226f6f",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "\n",
    "Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b76899-1423-4050-85e7-2a9b75487a50",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa05ba5-1490-4a88-80d2-1e4944b48a39",
   "metadata": {},
   "source": [
    "Q1. Bayes' Theorem:\n",
    "\n",
    "Bayes' theorem is a rule in probability theory that allows you to calculate the posterior probability of an event (hypothesis) occurring given some evidence. In simpler terms, it helps you update your belief about the probability of something being true after considering new evidence.\n",
    "\n",
    "Q2. Formula:\n",
    "\n",
    "P(B | A) = (P(A | B) * P(B)) / P(A)\n",
    "\n",
    "P(B | A): The posterior probability of event B happening given that event A has already occurred.\n",
    "\n",
    "P(A | B): The likelihood of observing event A if event B is true.\n",
    "\n",
    "P(B): The prior probability of event B occurring before considering any evidence.\n",
    "\n",
    "P(A): The prior probability of event A occurring before considering any evidence.\n",
    "\n",
    "Q3. Applications of Bayes' Theorem:\n",
    "\n",
    "Spam filtering: Classifying emails as spam or not spam based on keywords and other features.\n",
    "\n",
    "Medical diagnosis: Determining the probability of a disease based on symptoms and test results.\n",
    "\n",
    "Image recognition: Identifying objects in an image based on their features.\n",
    "\n",
    "Q4. Relationship with Conditional Probability:\n",
    "\n",
    "Conditional probability, P(A | B), represents the probability of event A happening given that event B has already occurred. Bayes' theorem allows you to calculate this conditional probability based on the likelihood (P(B | A)) and prior probabilities (P(A) and P(B)).\n",
    "\n",
    "Q5. Choosing a Naive Bayes Classifier:\n",
    "\n",
    "There are different types of Naive Bayes classifiers based on the assumed distribution of the features. Choosing the right one depends on the data:\n",
    "\n",
    "Gaussian Naive Bayes: Assumes features follow a Gaussian (normal) distribution. Suitable for continuous features.\n",
    "\n",
    "Multinomial Naive Bayes: Assumes features follow a multinomial distribution (e.g., word counts in text). Suitable for discrete features.\n",
    "\n",
    "Bernoulli Naive Bayes: Assumes features are binary (e.g., presence or absence of a word). Suitable for binary features.\n",
    "\n",
    "Q6. Assigning a New Instance:\n",
    "\n",
    "Here's how to solve the given assignment using Naive Bayes with equal prior probabilities (P(A) = P(B) = 0.5):\n",
    "\n",
    "Calculate class-conditional probabilities:\n",
    "\n",
    "P(X1=3 | A) = 4/7 (count of X1=3 in class A divided by total instances in A)\n",
    "\n",
    "P(X2=4 | A) = 3/7 (similarly for X2=4 in A)\n",
    "\n",
    "P(X1=3 | B) = 1/7 (count of X1=3 in class B divided by total instances in B)\n",
    "\n",
    "P(X2=4 | B) = 3/7 (similarly for X2=4 in B)\n",
    "\n",
    "Calculate posterior probabilities:\n",
    "\n",
    "P(A | X1=3, X2=4) = (P(X1=3 | A) * P(X2=4 | A) * P(A)) / P(X1=3, X2=4)\n",
    "\n",
    "P(B | X1=3, X2=4) = (P(X1=3 | B) * P(X2=4 | B) * P(B)) / P(X1=3, X2=4)\n",
    "\n",
    "Compare posterior probabilities: Since the prior probabilities are equal, compare the product of class-conditional probabilities for each class.\n",
    "\n",
    "Without calculating the exact values, we can see that the product of class-conditional probabilities for class A (P(X1=3 | A) * P(X2=4 | A)) will be higher than for class B due to higher individual probabilities. Therefore, Naive Bayes would predict the new instance (X1=3, X2=4) to belong to class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afcc244-ddda-45b1-b7fe-4a9d69202ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
