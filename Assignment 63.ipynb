{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d414d53-50f1-47a6-9c2b-7ce82bea013a",
   "metadata": {},
   "source": [
    "Q1. What is the KNN algorithm?\n",
    "\n",
    "Q2. How do you choose the value of K in KNN?\n",
    "\n",
    "Q3. What is the difference between KNN classifier and KNN regressor?\n",
    "\n",
    "Q4. How do you measure the performance of KNN?\n",
    "\n",
    "Q5. What is the curse of dimensionality in KNN?\n",
    "\n",
    "Q6. How do you handle missing values in KNN?\n",
    "\n",
    "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?\n",
    "\n",
    "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?\n",
    "\n",
    "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n",
    "\n",
    "Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bee8b3-1637-4669-814d-4ea3fa657394",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee33cd3-10aa-4893-a2f2-8158f3f258f1",
   "metadata": {},
   "source": [
    "Q1. KNN (K-Nearest Neighbors) is a supervised learning algorithm that classifies or predicts the value of a new data point based on the k closest data points in the training set.\n",
    "\n",
    "Q2. Choosing the optimal k in KNN is empirical and often involves trying different values and evaluating their performance on a validation set.\n",
    "\n",
    "Q3. KNN classifier: predicts discrete class labels. KNN regressor: predicts continuous values.\n",
    "\n",
    "Q4. Accuracy, precision, recall, F1-score, and root mean squared error (RMSE) are common metrics for KNN classifiers and regressors, respectively.\n",
    "\n",
    "Q5. Curse of dimensionality: KNN performance deteriorates as the number of features increases due to the difficulty of finding meaningful distances in high-dimensional space.\n",
    "\n",
    "Q6. Imputation techniques are used to estimate missing values before applying the KNN algorithm.\n",
    "\n",
    "Q7. Both KNN classifier and regressor perform well for small datasets and simple problems, but their accuracy can suffer in high dimensions. KNN classifiers are suited for classification tasks, while KNN regressors are for regression tasks.\n",
    "\n",
    "Q8. Strengths: Simple, interpretable, effective for small datasets. Weaknesses: High training time, sensitive to irrelevant features, curse of dimensionality. Address weaknesses: Feature selection, dimensionality reduction, efficient data structures.\n",
    "\n",
    "Q9. Euclidean distance measures the straight-line distance between points. Manhattan distance measures the sum of the absolute differences in corresponding coordinates.\n",
    "\n",
    "Q10. Feature scaling normalizes features to a similar range, improving the performance of KNN by preventing features with larger scales from dominating distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76670f7-5237-4370-a861-ae9085a6e4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
