{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842988c3-eda6-4d73-a55a-afe1702d7841",
   "metadata": {},
   "source": [
    "Q1. What is a projection and how is it used in PCA?\n",
    "\n",
    "Q2. How does the optimization problem in PCA work, and what is it trying to achieve?\n",
    "\n",
    "Q3. What is the relationship between covariance matrices and PCA?\n",
    "\n",
    "Q4. How does the choice of number of principal components impact the performance of PCA?\n",
    "\n",
    "Q5. How can PCA be used in feature selection, and what are the benefits of using it for this purpose?\n",
    "\n",
    "Q6. What are some common applications of PCA in data science and machine learning?\n",
    "\n",
    "Q7.What is the relationship between spread and variance in PCA?\n",
    "\n",
    "Q8. How does PCA use the spread and variance of the data to identify principal components?\n",
    "\n",
    "Q9. How does PCA handle data with high variance in some dimensions but low variance in others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e984e-eadd-4591-82db-5c0731592592",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9c117-7c87-4b9a-9f1e-cbafbc7e0871",
   "metadata": {},
   "source": [
    "Q1. Projection in PCA:\n",
    "\n",
    "Projection: Transforming data points onto a lower-dimensional subspace that captures the most significant information.\n",
    "\n",
    "In PCA: Projections are onto the principal components (PCs), which are directions with the highest variance.\n",
    "\n",
    "Q2. Optimization in PCA:\n",
    "\n",
    "Objective: Find a set of orthonormal (perpendicular) directions capturing the maximum variance in the data.\n",
    "\n",
    "Optimization problem: Mathematically, the solution involves finding eigenvectors and eigenvalues of the covariance matrix.\n",
    "\n",
    "Q3. Covariance Matrix and PCA:\n",
    "\n",
    "Covariance matrix: Captures the linear relationship between features.\n",
    "\n",
    "PCA uses the covariance matrix to identify directions (PCs) where data points exhibit the most spread (variance).\n",
    "\n",
    "Q4. Choosing the Number of Principal Components:\n",
    "\n",
    "More PCs: Captures more variance but might introduce noise.\n",
    "\n",
    "Fewer PCs: Captures less variance but reduces dimensionality more.\n",
    "\n",
    "Choice: Often determined by explained variance ratio (percentage of variance captured) or information loss tolerance.\n",
    "\n",
    "Q5. PCA for Feature Selection:\n",
    "\n",
    "Selection: Selecting features corresponding to PCs with significant variance.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "Removes redundant or irrelevant features.\n",
    "\n",
    "Reduces dimensionality and improves computational efficiency of other algorithms.\n",
    "\n",
    "Q6. Applications of PCA:\n",
    "\n",
    "** dimensionality reduction** for visualization, anomaly detection, and data compression.\n",
    "\n",
    "feature selection for machine learning models.\n",
    "\n",
    "pre-processing for improving the performance of other algorithms.\n",
    "\n",
    "Q7. Spread and Variance in PCA:\n",
    "\n",
    "Spread: Refers to the dispersion of data points around the mean.\n",
    "\n",
    "Variance: Quantifies the spread mathematically (square of the standard deviation).\n",
    "\n",
    "PCA identifies PCs that capture the directions with the highest variance (greatest spread).\n",
    "\n",
    "Q8. Identifying Principal Components:\n",
    "\n",
    "PCA analyzes the covariance matrix to find eigenvectors (directions) and eigenvalues (associated variance).\n",
    "\n",
    "PCs: Correspond to the eigenvectors with the highest eigenvalues, indicating the directions with the most spread (variance) in the data.\n",
    "\n",
    "Q9. Handling Uneven Variance:\n",
    "\n",
    "Standardization/Normalization: Pre-processing step to scale features to have similar variance before applying PCA.\n",
    "\n",
    "PCA is sensitive to scaling: Uneven variance can bias the analysis towards features with larger scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01991d21-1904-4a64-a442-a9bfc53a0c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
