{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e2fcc9-0411-420e-8a43-2a44ea65bfde",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n",
    "\n",
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\n",
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.\n",
    "\n",
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7137d77-dba1-4d7a-8616-f02d0d80281b",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d62ed5-748c-4025-9c56-b11abac6dca0",
   "metadata": {},
   "source": [
    "Q1. ANOVA Assumptions and Violations:\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "Normality: Residuals (errors) are normally distributed.\n",
    "\n",
    "Homogeneity of variance: Variances of groups are equal.\n",
    "\n",
    "Independence: Observations are independent of each other.\n",
    "\n",
    "Violations:\n",
    "\n",
    "Non-normality: Can lead to inaccurate p-values and affect F-statistic.\n",
    "\n",
    "Heterogeneity of variance: Can inflate or deflate F-statistic, affecting significance testing.\n",
    "\n",
    "Dependence: Can lead to biased estimates and unreliable conclusions.\n",
    "\n",
    "Mitigation:\n",
    "\n",
    "Transformations: Logarithmic or square root transformations can help achieve normality.\n",
    "\n",
    "Welch's ANOVA: More robust to unequal variances.\n",
    "\n",
    "Non-parametric tests: Kruskal-Wallis test doesn't require normality.\n",
    "\n",
    "Q2. Types of ANOVA:\n",
    "\n",
    "One-way ANOVA: Compares means of several independent groups (e.g., three dietary groups).\n",
    "\n",
    "Two-way ANOVA: Compares means of groups with two factors (e.g., software programs and experience levels).\n",
    "\n",
    "Repeated measures ANOVA: Analyzes data where the same subjects are measured on multiple occasions under different conditions (e.g., daily \n",
    "sales of three stores).\n",
    "\n",
    "Q3. Partitioning of Variance:\n",
    "\n",
    "Total sum of squares (SST): Total variation in the data.\n",
    "\n",
    "Explained sum of squares (SSE): Variation explained by the group differences.\n",
    "\n",
    "Residual sum of squares (SSR): Variation due to random error.\n",
    "\n",
    "Importance:\n",
    "\n",
    "Helps understand the proportion of variance attributable to group differences and random error.\n",
    "\n",
    "Used to calculate the F-statistic for testing null hypothesis (no difference between groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f74275-fb6c-442c-8a47-770dbda69e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.4\n",
    "'''import numpy as np\n",
    "\n",
    "def calculate_sums_of_squares(data, groups):\n",
    "  \"\"\"Calculates sums of squares in ANOVA.\"\"\"\n",
    "  n = len(data)\n",
    "  grand_mean = np.mean(data)\n",
    "  \n",
    "  SST = np.sum([(x - np.mean(group))**2 for x, group in zip(data, groups)])\n",
    "  \n",
    "  unique_groups = np.unique(groups)\n",
    "  group_means = [np.mean(data[groups == group]) for group in unique_groups]\n",
    "  SSE = np.sum([(group_mean - grand_mean)**2 * np.sum(groups == group) for group_mean in group_means])\n",
    "  \n",
    "  SSR = SST - SSE\n",
    "  return SST, SSE, SSR'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db249e4-5320-4de4-9cbd-73721fc4f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.5\n",
    "'''import statsmodels.api as sm\n",
    "\n",
    "model = sm.MixedLM.from_formula('outcome ~ factor1 + factor2 + factor1*factor2', data=your_data)\n",
    "fit_results = model.fit()\n",
    "\n",
    "print(fit_results.summary())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4444d9a-3259-475e-b177-6833683223f9",
   "metadata": {},
   "source": [
    "Q6. Interpreting ANOVA Results (F = 5.23, p-value = 0.02):\n",
    "\n",
    "The F-statistic (5.23) indicates a potential difference between group means.\n",
    "\n",
    "The p-value (0.02) is less than 0.05, rejecting the null hypothesis at a 5% significance level.\n",
    "\n",
    "We can conclude that there is a statistically significant difference between at least one pair of group means.\n",
    "\n",
    "Further analysis: Post-hoc tests (e.g., Tukey's HSD) are needed to identify which specific groups differ significantly.\n",
    "\n",
    "Q7. Handling Missing Data in Repeated Measures ANOVA:\n",
    "\n",
    "Deletion: Simplest but can lead to loss of information and reduced power.\n",
    "\n",
    "Mean imputation: Impute missing values with the mean value of the variable.\n",
    "\n",
    "Last observation carried forward (LOCF): Use the previous value for missing observations.\n",
    "\n",
    "Consequences:\n",
    "\n",
    "Deletion can bias results and reduce power.\n",
    "\n",
    "Imputation methods can introduce bias depending on the missing data mechanism.\n",
    "\n",
    "Q8. Common Post-hoc Tests and Applications:\n",
    "\n",
    "Tukey's HSD: Compares all possible pairs of means, good for equal sample sizes and few comparisons.\n",
    "\n",
    "Scheffe's test: More conservative than Tukey's HSD, suitable for unequal sample sizes or many comparisons.\n",
    "\n",
    "Bonferroni correction: Adjusts p-values for multiple comparisons, controlling for Type I error inflation.\n",
    "\n",
    "Example: Use post-hoc tests after ANOVA to determine which dietary groups differ in weight loss.\n",
    "\n",
    "\n",
    "Q10. The Isolation Forest algorithm implicitly detects global outliers by assigning higher anomaly scores to data points that are easier to isolate (i.e., require shorter path lengths across the trees).\n",
    "\n",
    "Data points with significantly shorter path lengths compared to the average path length across the trees are likely further away from the majority of the data and are considered potential global outliers.\n",
    "\n",
    "Q11. Local outlier detection:\n",
    "\n",
    "Fraud detection: Analyzing individual transactions for deviations from user's typical spending behavior.\n",
    "\n",
    "Sensor network anomaly detection: Identifying unusual readings from a specific device compared to historical data.\n",
    "\n",
    "Image anomaly detection: Detecting anomalies within specific image regions (e.g., unusual textures or objects).\n",
    "\n",
    "Global outlier detection:\n",
    "\n",
    "Credit card fraud detection: Identifying transactions with extremely high amounts or unusual locations.\n",
    "\n",
    "Weather anomaly detection: Detecting extreme temperature or pressure readings across a large region.\n",
    "\n",
    "Stock market anomaly detection: Identifying stocks with significant price fluctuations compared to market trends.\n",
    "\n",
    "Q12. How does the epsilon parameter affect the performance of DBSCAN in detecting anomalies?\n",
    "\n",
    "The epsilon parameter (eps) in DBSCAN controls the size of the neighborhood considered around a data point. It directly impacts the algorithm's ability to detect anomalies:\n",
    "\n",
    "Smaller epsilon:\n",
    "\n",
    "Creates smaller clusters, potentially capturing local anomalies that deviate from their immediate neighbors.\n",
    "\n",
    "May miss global anomalies if they are further away from other points in the dense region.\n",
    "\n",
    "Larger epsilon:\n",
    "\n",
    "May miss local anomalies if they are not densely surrounded by similar points.\n",
    "\n",
    "Can be more effective in capturing global anomalies that stand out significantly from the overall data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ff669-2c16-4e71-923b-bd5da193a02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
